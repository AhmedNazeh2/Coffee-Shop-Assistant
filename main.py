import streamlit as st
import time
from graph import create_agent
from langchain_core.messages import HumanMessage, AIMessage


# Fixed customer_id and thread_id for this single-session application
FIXED_CUSTOMER_ID = "single_coffee_customer" 
LANGGRAPH_CONFIG = {
    "configurable": {
        "thread_id": FIXED_CUSTOMER_ID,
        "recursion_limit": 50
    }
}

# Initialize the LangGraph Agent 
app = create_agent()

# --- Streamlit Page Setup ---
st.set_page_config(page_title="Ù…Ø³Ø§Ø¹Ø¯ Ù‚Ù‡ÙˆØ© Ù…Ù‚Ù‡Ù‰ Ø§Ù„Ù„Ø¤Ù„Ø¤Ø©", layout="centered")
st.title("Ù…Ø³Ø§Ø¹Ø¯ Ù‚Ù‡ÙˆØ© Ù…Ù‚Ù‡Ù‰ Ø§Ù„Ù„Ø¤Ù„Ø¤Ø© â˜•")

# Chat History Display Function
def display_chat_history(app_instance, config_dict):
    """Displays messages from the LangGraph history for the current fixed session."""
    
    with st.chat_message("assistant"):
        st.markdown("<div dir='rtl'>Ø£Ù‡Ù„Ø§Ù‹ Ø¨Ùƒ ÙÙŠ Ù…Ù‚Ù‡Ù‰ Ø§Ù„Ù„Ø¤Ù„Ø¤Ø©! Ø£Ù†Ø§ Ù…Ø³Ø§Ø¹Ø¯Ùƒ Ø§Ù„Ø´Ø®ØµÙŠ Ù‡Ù†Ø§. ÙƒÙŠÙ ÙŠÙ…ÙƒÙ†Ù†ÙŠ Ù…Ø³Ø§Ø¹Ø¯ØªÙƒ Ø§Ù„ÙŠÙˆÙ…ØŸ ØªÙØ¶Ù„ Ø¨Ø·Ù„Ø¨Ùƒ Ø£Ùˆ Ø§Ø³Ø£Ù„ Ø¹Ù† Ù‚Ø§Ø¦Ù…ØªÙ†Ø§!</div>", unsafe_allow_html=True)
    
    history = app_instance.get_state(config_dict)
    
    # Check if there are no messages in history
    if not history:
        return
    
    messages = history.values.get('messages', [])
    
    for msg in messages:
        if isinstance(msg, HumanMessage):
            with st.chat_message("user"):
                st.markdown(f"<div dir='rtl'>{msg.content}</div>", unsafe_allow_html=True)
        elif isinstance(msg, AIMessage):
            # Displays only the final AI messages that do not contain tool calls,
            # indicating a complete response from the assistant for that turn.
            if not msg.tool_calls:
                with st.chat_message("assistant"):
                    st.markdown(f"<div dir='rtl'>{msg.content}</div>", unsafe_allow_html=True)

# Stream Agent Response Function
def stream_response(graph_app, initial_state, config_for_run):
    """Streams the agent's response and updates status messages."""

    with st.status("Ø§Ù„ÙˆÙƒÙŠÙ„ ÙŠÙÙƒØ±...", expanded=True) as status_container:

        for step in graph_app.stream(initial_state, config=config_for_run):
            # LangGraph step will have a single key representing the node that just ran
            node_name = list(step.keys())[0] 
            node_value = step[node_name]
            
            # Update status message based on the current node
            if node_name == "Process_node":
                status_container.update(label="Ø§Ù„ÙˆÙƒÙŠÙ„ ÙŠØ¬Ù‡Ø² Ø±Ø¯Ù‡ Ø£Ùˆ ÙŠØ­Ø¯Ø¯ Ø§Ù„Ø£Ø¯Ø§Ø©... ğŸ§ ")
                
            elif node_name == "tools_node":
                tool_name = node_value['messages'][0].name
                
                # Refine these messages based on specific tool names
                if tool_name == "get_menu_items":
                    status_container.update(label="Ø¬Ø§Ø±ÙŠ Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ù…Ø´Ø±ÙˆØ¨Ø§Øª... ğŸ“‹")
                elif tool_name == "get_item_details":
                    status_container.update(label="Ø¬Ø§Ø±ÙŠ Ø§Ø³ØªØ¹Ø±Ø§Ø¶ ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ù…Ù†ØªØ¬... ğŸ”")
                elif tool_name == "place_order":
                    status_container.update(label="Ø¬Ø§Ø±ÙŠ ØªØ³Ø¬ÙŠÙ„ Ø·Ù„Ø¨Ùƒ... âœï¸")
                elif tool_name == "get_order_status":
                    status_container.update(label="Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø­Ø§Ù„Ø© Ø§Ù„Ø·Ù„Ø¨... ğŸ“Š")
                elif tool_name == "cancel_order":
                    status_container.update(label=f"Ø¬Ø§Ø±ÙŠ Ø¥Ù„ØºØ§Ø¡ Ø§Ù„Ø·Ù„Ø¨... âŒ")
                else:
                    status_container.update(label=f"ØªÙ†ÙÙŠØ° Ø£Ø¯Ø§Ø©: {tool_name}... ğŸ› ï¸")
                    
            time.sleep(1)
        status_container.update(label="Ø§Ù†ØªÙ‡ÙŠØª... âœ…")
        time.sleep(1)


# Main Application Logic
if __name__ == "__main__":
    
    # Display the chat history.
    display_chat_history(app, LANGGRAPH_CONFIG)

    # Get user input at the bottom of the chat interface
    if prompt := st.chat_input("ÙƒÙŠÙ ÙŠÙ…ÙƒÙ†Ù†ÙŠ Ù…Ø³Ø§Ø¹Ø¯ØªÙƒØŸ"):
        # Display the user's message
        with st.chat_message("user"):
            st.markdown(f"<div dir='rtl'>{prompt}</div>", unsafe_allow_html=True)
        
        # Stream the assistant's response
        with st.chat_message("assistant"):
            # Prepare the initial state for the LangGraph agent run
            initial_state = {
                "messages": [HumanMessage(content=prompt)],
                "customer_id": FIXED_CUSTOMER_ID
            }
            stream_response(app, initial_state, LANGGRAPH_CONFIG)
        
        # Rerun the Streamlit app to update the chat history from LangGraph's memory
        st.rerun()